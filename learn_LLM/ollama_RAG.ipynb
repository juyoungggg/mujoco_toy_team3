{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "683cbdd9",
   "metadata": {},
   "source": [
    "Qwen3 (0.6B) ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬, [ì‹¤ìŠµ 1: LLMì„ í•¨ìˆ˜ì²˜ëŸ¼ ì‚¬ìš©í•˜ê¸°]ì™€ [ì‹¤ìŠµ 2: ë¬¸ì„œ ê¸°ë°˜ ì „ë¬¸ê°€(On-Device RAG)] ì§„í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e7aa395",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76162b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qwen3ëŠ” ì¶”ë¡  ëŠ¥ë ¥ì´ ê°•í™”ë˜ì–´ ì‘ì€ ì‚¬ì´ì¦ˆë¡œë„ ë˜‘ë˜‘í•œ ëŒ€ë‹µì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n",
    "# temperature=0: ì°½ì˜ì„±ì„ 0ìœ¼ë¡œ ë‚®ì¶”ì–´, í•­ìƒ ì¼ê´€ë˜ê³  ì‚¬ì‹¤ì ì¸ ë‹µë³€ë§Œ í•˜ë„ë¡ ì„¤ì • (ë°ì´í„° ì¶”ì¶œì— í•„ìˆ˜)\n",
    "llm = ChatOllama(model=\"qwen3:0.6b\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c10086",
   "metadata": {},
   "source": [
    "[ì‹¤ìŠµ 1] LLMì„ í•¨ìˆ˜ì²˜ëŸ¼ ì‚¬ìš©í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f743f57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few-shot í”„ë¡¬í”„íŠ¸ (ì˜ˆì‹œë¥¼ ì£¼ì…)\n",
    "# ëª¨ë¸ì—ê²Œ \"ì—¬ëŸ¬ ê°œê°€ ë‚˜ì˜¤ë©´ ë¦¬ìŠ¤íŠ¸([])ë¡œ ë¬¶ì–´ë¼\"ëŠ” ê²ƒì„ ì˜ˆì‹œë¡œ í•™ìŠµì‹œí‚µë‹ˆë‹¤.\n",
    "template = \"\"\"\n",
    "You are a precise Data Extraction Module.\n",
    "Extract hardware status from the input text into a JSON List format.\n",
    "\n",
    "Examples:\n",
    "Input: \"Battery is 12V and Camera is OK.\"\n",
    "Output: [\n",
    "    {{\"component\": \"Battery\", \"status\": \"Normal\", \"value\": 12}},\n",
    "    {{\"component\": \"Camera\", \"status\": \"OK\", \"value\": null}}\n",
    "]\n",
    "\n",
    "Input: {input}\n",
    "Output:\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e72b3403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\"component\": \"LiDAR sensor\", \"status\": \"Normal\", \"value\": 12},\n",
      "    {\"component\": \"motor\", \"status\": \"Warning\", \"value\": null}\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# ì˜ˆ: \"ì§€ê¸ˆ ë¼ì´ë‹¤ ì„¼ì„œëŠ” ì •ìƒ, ëª¨í„° ì˜¨ë„ ê²½ê³  ìƒíƒœ\"\n",
    "user_input = \"LiDAR ì„¼ì„œ-> ì •ìƒ ì‘ë™ ì¤‘, ëª¨í„° ì˜¨ë„ê°€ 45ë„ë¼ì„œ ê²½ê³  ìƒíƒœì•¼.\"\n",
    "\n",
    "response = chain.invoke({\"input\": user_input})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d63ec3",
   "metadata": {},
   "source": [
    "**[ì‹¤ìŠµ 2]: ë¬¸ì„œ ê¸°ë°˜ ì „ë¬¸ê°€(On-Device RAG)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db4a7055",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from pypdf import PdfReader\n",
    "\n",
    "# ì„¤ì • ë° API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”(ì„ë² ë”© ë‹´ë‹¹)\n",
    "load_dotenv()\n",
    "api_key = os.environ.get(\"GEMINI_API_KEY\")\n",
    "client = genai.Client(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1820f7d",
   "metadata": {},
   "source": [
    "ìœ í‹¸ í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c299ade9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„ë² ë”© ë° ê²€ìƒ‰ í•¨ìˆ˜ ì •ì˜ (Geminiì˜ 'ëˆˆ' ì—­í• )\n",
    "def get_embedding(text, task_type=\"RETRIEVAL_DOCUMENT\"):\n",
    "    response = client.models.embed_content(\n",
    "        model=\"text-embedding-004\",\n",
    "        contents=text,\n",
    "        config=types.EmbedContentConfig(task_type=task_type)\n",
    "    )\n",
    "    return response.embeddings[0].values\n",
    "\n",
    "def search_pdf(query, chunks, chunk_embeddings):\n",
    "    # ì§ˆë¬¸ì„ ë²¡í„°ë¡œ ë³€í™˜\n",
    "    query_vec = get_embedding(query, task_type=\"RETRIEVAL_QUERY\")\n",
    "    \n",
    "    # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°\n",
    "    scores = [np.dot(query_vec, doc_vec) for doc_vec in chunk_embeddings]\n",
    "    best_idx = np.argmax(scores)\n",
    "    \n",
    "    return chunks[best_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e16233",
   "metadata": {},
   "source": [
    "ë©”ì¸ ì‹¤í–‰ ë¡œì§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25ab1130",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 10 0 (offset 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF 'src/syllabus.pdf' ë¡œë”© ë° ì²˜ë¦¬ ì¤‘...\n",
      "Vectorizing 5 pages... (Gemini Embedding)\n",
      "ë²¡í„°í™” ì™„ë£Œ!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PDF ì½ê¸° ë° ë²¡í„°í™” (ë°ì´í„° ì¤€ë¹„)\n",
    "pdf_path = \"src/syllabus.pdf\" \n",
    "print(f\"PDF '{pdf_path}' ë¡œë”© ë° ì²˜ë¦¬ ì¤‘...\")\n",
    "\n",
    "reader = PdfReader(pdf_path)\n",
    "chunks = [page.extract_text() for page in reader.pages if page.extract_text()]\n",
    "\n",
    "# Geminië¡œ ë¬¸ì„œ ì „ì²´ ì„ë² ë”© (ìµœì´ˆ 1íšŒ ì‹¤í–‰)\n",
    "print(f\"Vectorizing {len(chunks)} pages... (Gemini Embedding)\")\n",
    "chunk_embeddings = [get_embedding(chunk) for chunk in chunks]\n",
    "print(\"ë²¡í„°í™” ì™„ë£Œ!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b2d53a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¹„êµí•  ì§ˆë¬¸\n",
    "test_question = \"ì´ë²ˆ ëª¨ë¹Œë¦¬í‹°S/Wí™œìš©II ê³¼ëª©ì˜ êµìˆ˜ ì´ë¦„ê³¼ ê°•ì˜ì‹¤, ê·¸ë¦¬ê³  ì´ë©”ì¼ì„ ì•Œë ¤ì¤˜. ë˜ 1ì¼ì°¨ ìˆ˜ì—… ë‚´ìš©ì„ ìš”ì•½í•´ì¤˜\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ae138c",
   "metadata": {},
   "source": [
    "[Case 1] âŒ RAG ì ìš© ì „"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25e53f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [âŒ RAG ì ìš© ì „ ì§ˆë¬¸: ì´ë²ˆ ëª¨ë¹Œë¦¬í‹°S/Wí™œìš©II ê³¼ëª©ì˜ êµìˆ˜ ì´ë¦„ê³¼ ê°•ì˜ì‹¤, ê·¸ë¦¬ê³  ê°•ì˜ ì‹œê°„ ë° ìš”ì¼ì„ ì•Œë ¤ì¤˜.] ---\n",
      "í˜„ì¬ ì§„í–‰ ì¤‘ì¸ \"ëª¨ë¹Œë¦¬í‹° S/W í™œìš© II\" ê³¼ëª© ê´€ë ¨ ì •ë³´ëŠ” ì‹¤ì‹œê°„ìœ¼ë¡œ ì œê³µë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì•„ë˜ì™€ ê°™ì´ ì¼ë°˜ì ì¸ ì •ë³´ë¥¼ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤:  \n",
      "- **êµìˆ˜ ì´ë¦„**: [êµìˆ˜ ì´ë¦„ ì…ë ¥]  \n",
      "- **ê°•ì˜ì‹¤**: [ê°•ì˜ì‹¤ ë²ˆí˜¸/ì£¼ì†Œ]  \n",
      "- **ê°•ì˜ ì‹œê°„**: [ê°•ì˜ ì‹œê°„]  \n",
      "- **ìš”ì¼**: [ìš”ì¼]  \n",
      "\n",
      "ì´ ì •ë³´ê°€ ì‹¤ì œ ê³¼ëª© ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì œê³µë˜ëŠ”ì§€ í™•ì¸í•´ ì£¼ì„¸ìš”. í•„ìš”ì‹œ ì¶”ê°€ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì‹œë©´ ë” êµ¬ì²´ì ì¸ ë‹µë³€ì„ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "-------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"--- [âŒ RAG ì ìš© ì „ ì§ˆë¬¸: {test_question}] ---\")\n",
    "\n",
    "template_no_rag = \"\"\"\n",
    "ì§ˆë¬¸ì— ë‹µë³€í•´ ì£¼ì„¸ìš”.\n",
    "ì§ˆë¬¸: {question}\n",
    "\"\"\"\n",
    "prompt_no_rag = ChatPromptTemplate.from_template(template_no_rag)\n",
    "\n",
    "# Chain ì‹¤í–‰\n",
    "chain_no_rag = prompt_no_rag | llm | StrOutputParser()\n",
    "response_before = chain_no_rag.invoke({\"question\": test_question})\n",
    "\n",
    "print(response_before)\n",
    "print(\"-------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01d490c",
   "metadata": {},
   "source": [
    "[Case 2] âœ… RAG ì ìš© í›„ (ê²€ìƒ‰ + ë‹µë³€)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68f018b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [RAG ì ìš© í›„ ì§ˆë¬¸: ì´ë²ˆ ëª¨ë¹Œë¦¬í‹°S/Wí™œìš©II ê³¼ëª©ì˜ êµìˆ˜ ì´ë¦„ê³¼ ê°•ì˜ì‹¤, ê·¸ë¦¬ê³  ì´ë©”ì¼ì„ ì•Œë ¤ì¤˜. ë˜ 1ì¼ì°¨ ìˆ˜ì—… ë‚´ìš©ì„ ìš”ì•½í•´ì¤˜] ---\n",
      "ğŸ” [ê²€ìƒ‰ëœ ë¬¸ì„œ ë‚´ìš© ì¼ë¶€]:\n",
      "ìˆ˜ ì—… ê³„ íš ì„œ\n",
      "( 2 0 2 5 í•™ ë…„ ë„ ê²¨ ìš¸ í•™ ê¸° )\n",
      "1 / 5\n",
      "ë‹¨ ê³¼ ëŒ€ í•™ ì—° ê³„ ì „ ê³µ ë°° ì • í•™ ê³¼ ë¯¸ ë˜ ì ë™ ì°¨ ì „ ê³µ\n",
      "ê³¼ ëª© ëª… ëª¨ ë¹Œ ë¦¬ í‹° S / W ...\n",
      "\n",
      "Qwen(qwen3:0.6b)ì˜ RAG ë‹µë³€:\n",
      "- **Teacher's Name**: ì´ ìŠ¹ ëª©  \n",
      "- **Class Room**: 5 ì¸µ 8 í˜¸ ì‹¤  \n",
      "- **Email**: s e u n g m o k @ k o o k m i n . a c . k r  \n",
      "- **1-Day Class Summary**: ì „ ê³µ êµ ê³¼ ëª© ìœ  í˜• (Class: Public Education, Subject: Form)  \n",
      "\n",
      "I don't know.\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(f\"--- [RAG ì ìš© í›„ ì§ˆë¬¸: {test_question}] ---\")\n",
    "\n",
    "# 1) ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë¬¸ì„œ ë‚´ìš©(Context) ê²€ìƒ‰\n",
    "found_context = search_pdf(test_question, chunks, chunk_embeddings)\n",
    "print(f\"ğŸ” [ê²€ìƒ‰ëœ ë¬¸ì„œ ë‚´ìš© ì¼ë¶€]:\\n{found_context[:100]}...\\n\")\n",
    "\n",
    "# 2) RAG ì „ìš© í”„ë¡¬í”„íŠ¸ ì •ì˜\n",
    "rag_template = \"\"\"\n",
    "You are a helpful assistant. Answer the question based ONLY on the context below.\n",
    "If the answer is not in the context, say \"I don't know\".\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "rag_prompt = ChatPromptTemplate.from_template(rag_template)\n",
    "\n",
    "# 3) Chain ì‹¤í–‰ (Contextì™€ Questionì„ í•¨ê»˜ ì£¼ì…)\n",
    "rag_chain = rag_prompt | llm | StrOutputParser()\n",
    "response_after = rag_chain.invoke({\n",
    "    \"context\": found_context,   # ê²€ìƒ‰í•œ ë‚´ìš©\n",
    "    \"question\": test_question   # ì‚¬ìš©ì ì§ˆë¬¸\n",
    "})\n",
    "\n",
    "print(f\"Qwen({llm.model})ì˜ RAG ë‹µë³€:\")\n",
    "print(response_after)\n",
    "print(\"-------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mujoco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
