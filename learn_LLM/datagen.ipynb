{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2620a074",
   "metadata": {},
   "source": [
    "파인튜닝용 데이터셋 생성 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "413e6101",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "from tqdm.notebook import tqdm  # 진행바 표시용\n",
    "# PDF 처리용\n",
    "from langchain_community.document_loaders import PyMuPDFLoader \n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c9b18ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 설정\n",
    "load_dotenv()\n",
    "api_key = os.environ.get(\"GEMINI_API_KEY\")\n",
    "client = genai.Client(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2717683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. PDF 로드 및 분할 (PyMuPDFLoader 사용 - 속도/정확도/메타데이터 확보)\n",
    "def load_and_split_pdf(file_path):\n",
    "    print(f\"Loading PDF with PyMuPDF: {file_path}...\")\n",
    "    \n",
    "    # (1) 로드: 페이지별로 텍스트와 메타데이터(페이지번호 등)를 가져옵니다.\n",
    "    loader = PyMuPDFLoader(file_path)\n",
    "    docs = loader.load() \n",
    "    \n",
    "    # (2) 분할: 문맥을 고려해 자르되, 페이지 정보 등은 유지합니다.\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000, \n",
    "        chunk_overlap=100\n",
    "    )\n",
    "    chunks = text_splitter.split_documents(docs) # split_text가 아니라 split_documents 사용\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f579bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 데이터셋 생성 루프\n",
    "def generate_dataset_gemini(chunks, output_file=\"dataset.jsonl\"):\n",
    "    final_dataset = []\n",
    "    \n",
    "    # 프롬프트 설정\n",
    "    base_prompt = \"\"\"\n",
    "    당신은 6G 이동통신과 AI 분야의 전문가입니다. \n",
    "    아래 [Context]를 보고 학습용 질문-답변 쌍 3개를 JSON으로 만드세요.\n",
    "    \n",
    "    [Context] (Page {page_num})\n",
    "    {context}\n",
    "    \n",
    "    [Format]\n",
    "    {{ \"dataset\": [ {{ \"instruction\": \"...\", \"output\": \"...\" }} ] }}\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\" 데이터 생성 시작! (총 {len(chunks)} 단계)\")\n",
    "    \n",
    "    # 진행바와 함께 반복\n",
    "    for chunk in tqdm(chunks):\n",
    "        try:\n",
    "            # Gemini 1.5 Flash 호출 (JSON 모드 사용)\n",
    "            response = client.models.generate_content(\n",
    "                model='gemini-2.5-flash',\n",
    "                contents=base_prompt.format(\n",
    "                    context=chunk.page_content, \n",
    "                    page_num=chunk.metadata.get('page', 0) + 1\n",
    "                ),\n",
    "                config=types.GenerateContentConfig(\n",
    "                    temperature=0.5,\n",
    "                    response_mime_type=\"application/json\" \n",
    "                )\n",
    "            )\n",
    "            \n",
    "            # 결과 파싱 및 저장\n",
    "            data = json.loads(response.text)\n",
    "            if \"dataset\" in data:\n",
    "                for item in data[\"dataset\"]:\n",
    "                    final_dataset.append({\n",
    "                        \"instruction\": item[\"instruction\"],\n",
    "                        \"input\": \"\",\n",
    "                        \"output\": item[\"output\"]\n",
    "                    })\n",
    "            \n",
    "            time.sleep(3) # API 제한 방지용 잠깐 대기\n",
    "            \n",
    "        except Exception as e:\n",
    "            continue # 에러나면 무시하고 다음으로\n",
    "\n",
    "    # 파일로 저장\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        for entry in final_dataset:\n",
    "            f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
    "            \n",
    "    print(f\"\\n 저장 완료: {output_file} (총 {len(final_dataset)}개 데이터 쌍)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db3950e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PDF with PyMuPDF: src/6g_ai.pdf...\n",
      " 데이터 생성 시작! (총 77 단계)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23674e9d810c4abeb4bf1afe33f916fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/77 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 저장 완료: 6g_ai_dataset.jsonl (총 0개 데이터 쌍)\n"
     ]
    }
   ],
   "source": [
    "# PDF 파일 경로\n",
    "pdf_filename = \"src/6g_ai.pdf\" \n",
    "\n",
    "# 실행\n",
    "chunks = load_and_split_pdf(pdf_filename)\n",
    "generate_dataset_gemini(chunks, \"6g_ai_dataset.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997fe152",
   "metadata": {},
   "source": [
    "데이터 증강"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e0ca81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_dataset_gemini(input_file, output_file):\n",
    "    # 기존 데이터 로드\n",
    "    with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        original_data = [json.loads(line) for line in f]\n",
    "    \n",
    "    augmented_data = []\n",
    "    \n",
    "    # 증강 프롬프트 (질문 의미는 같게, 표현은 다르게)\n",
    "    aug_prompt = \"\"\"\n",
    "    아래 주어진 질문(Instruction)과 답변(Output)을 보고, \n",
    "    **답변은 그대로 유지하되 질문의 표현만 다르게 바꾼 유사 질문 3개**를 생성하세요.\n",
    "    \n",
    "    [Original]\n",
    "    Q: {instruction}\n",
    "    A: {output}\n",
    "    \n",
    "    [Format]\n",
    "    {{ \"variations\": [\"유사 질문 1\", \"유사 질문 2\", \"유사 질문 3\"] }}\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\" 데이터 증강 시작! (원본 {len(original_data)}개 -> 목표 약 {len(original_data)*4}개)\")\n",
    "\n",
    "    for entry in tqdm(original_data):\n",
    "        # 원본 데이터는 일단 그대로 추가\n",
    "        augmented_data.append(entry)\n",
    "        \n",
    "        try:\n",
    "            # Gemini 호출\n",
    "            response = client.models.generate_content(\n",
    "                model='gemini-2.5-flash',\n",
    "                contents=aug_prompt.format(\n",
    "                    instruction=entry['instruction'], \n",
    "                    output=entry['output']\n",
    "                ),\n",
    "                config=types.GenerateContentConfig(\n",
    "                    temperature=0.7, # 다양성을 위해 창의성 약간 높임\n",
    "                    response_mime_type=\"application/json\"\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            # 파싱 및 추가\n",
    "            data = json.loads(response.text)\n",
    "            if \"variations\" in data:\n",
    "                for new_q in data[\"variations\"]:\n",
    "                    augmented_data.append({\n",
    "                        \"instruction\": new_q,     # 새로 만든 질문\n",
    "                        \"input\": \"\",\n",
    "                        \"output\": entry['output'] # 답변은 원본 그대로 사용\n",
    "                    })\n",
    "            \n",
    "            time.sleep(3) # 속도 조절\n",
    "            \n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "    # 결과 저장\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        for entry in augmented_data:\n",
    "            f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
    "            \n",
    "    print(f\"\\n 증강 완료! 총 {len(augmented_data)}개 데이터가 '{output_file}'에 저장됨.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c2759fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 데이터 증강 시작! (원본 18개 -> 목표 약 72개)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2f872b17ab94be6aef9d80d83fc24fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 증강 완료! 총 27개 데이터가 '6g_ai_dataset_augmented.jsonl'에 저장됨.\n"
     ]
    }
   ],
   "source": [
    "augment_dataset_gemini(\"6g_ai_dataset.jsonl\", \"6g_ai_dataset_augmented.jsonl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mujoco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
